---
title: "RWorksheet#5_group(magallanes_Trongoy_Nava)"
author: "Killy Magallanes"
date: "2024-11-11"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Scraping the IMDb Top TV Shows and extracting the required data.


```{r}
library(dplyr)
library(rvest)
library(stringr)

url <- "https://www.imdb.com/chart/toptv/?sort=rank"
page <- read_html(url)


ranked_titles <- page %>%
  html_nodes(".titleColumn a") %>%
  html_text()
```

Placing in a data frame and splitting rank and title.

```{r}
title_data <- as.data.frame(ranked_titles[3:27], stringsAsFactors = FALSE)
colnames(title_data) <- "ranked_titles"
```

```{r}

split_titles <- strsplit(as.character(title_data$ranked_titles), "\\.", fixed = FALSE)
```

```{r}
title_df <- do.call(rbind, split_titles)
```


Cleaning the split


```{r}
if (ncol(title_df) == 2) {
  colnames(title_df) <- c("rank", "title")
} else {
  title_df <- data.frame(rank = rep(NA, length(split_titles)), 
                         title = as.character(split_titles))
}
```


Finalizing the data frame.


```{r}
title_df$title <- trimws(title_df$title)
```

Always save as CSV before proceeding. 


```{r}
write.csv(title_df, file = "movie_titles.csv", row.names=FALSE)
```


Scraping specifically the reviews of each movie.


```{r}

tv_show_links <- paste0("https://www.imdb.com/title/", 
                        c("tt0903747", "tt5491994", "tt0795176", "tt0185906", "tt7366338"), 
                        "/reviews/?ref_=tt_ov_urv")
```

Using of function to scrape from one page.

This chunk also includes the process of cleaning up the data.


```{r}

scrape_reviews <- function(link, desired_rows = 20) {
  page <- read_html(link)
  # Extract review details
  name <- page %>% html_nodes(".ipc-link.ipc-link--base") %>% html_text()
  year <- page %>% html_nodes(".ipc-inline-list__item.review-date") %>% html_text()
  rating <- page %>% html_nodes(".ipc-rating-star--rating") %>% html_text()
  title <- page %>% html_nodes(".ipc-title__text") %>% html_text()
  helpful <- page %>% html_nodes(".ipc-voting__label__count.ipc-voting__label__count--up") %>% html_text()
  unhelpful <- page %>% html_nodes(".ipc-voting__label__count.ipc-voting__label__count--down") %>% html_text()
  text <- page %>% html_nodes(".ipc-html-content-inner-div") %>% html_text()

  name <- c(name, rep(NA, max(0, desired_rows - length(name))))
  year <- c(year, rep(NA, max(0, desired_rows - length(year))))
  rating <- c(rating, rep(NA, max(0, desired_rows - length(rating))))
  title <- c(title, rep(NA, max(0, desired_rows - length(title))))
  helpful <- c(helpful, rep(NA, max(0, desired_rows - length(helpful))))
  unhelpful <- c(unhelpful, rep(NA, max(0, desired_rows - length(unhelpful))))
  text <- c(text, rep(NA, max(0, desired_rows - length(text))))
  
  name <- gsub("Permalink", "ANONYMOUS", name)
  name <- str_trim(name) 
  
  name <- c(name, rep(NA, max(0, desired_rows - length(name))))
  year <- c(year, rep(NA, max(0, desired_rows - length(year))))
  rating <- c(rating, rep(NA, max(0, desired_rows - length(rating))))
  title <- c(title, rep(NA, max(0, desired_rows - length(title))))
  helpful <- c(helpful, rep(NA, max(0, desired_rows - length(helpful))))
  unhelpful <- c(unhelpful, rep(NA, max(0, desired_rows - length(unhelpful))))
  text <- c(text, rep(NA, max(0, desired_rows - length(text))))
  
  name <- name[1:desired_rows]
  year <- year[1:desired_rows]
  rating <- rating[1:desired_rows]
  title <- title[1:desired_rows]
  helpful <- helpful[1:desired_rows]
  unhelpful <- unhelpful[1:desired_rows]
  text <- text[1:desired_rows]
  
  reviews <- data.frame(
    name = name,
    year = year,
    rating = rating,
    title = title,
    helpful = helpful,
    unhelpful = unhelpful,
    text = text,
    stringsAsFactors = FALSE
  )
  
  return(reviews)
}




```

Check if the data is correct.

```{r}
tv_show_links <- paste0("https://www.imdb.com/title/", 
                        c("tt0903747", "tt5491994", "tt0795176", "tt0185906", "tt7366338"), 
                        "/reviews/?ref_=tt_ov_urv")

all_reviews <- lapply(tv_show_links, scrape_reviews, desired_rows = 20)


combined_reviews <- do.call(rbind, all_reviews)
print(combined_reviews)
```

Always save as CSV.


```{r}
write.csv(combined_reviews, file = "movie_reviews.csv")
```


Combining all the data

```{r}

all_reviews <- lapply(tv_show_links, function(link) scrape_reviews(link, 20))
final_reviews <- bind_rows(all_reviews, .id = "tv_show_id")
final_reviews <- final_reviews %>%
  mutate(tv_show_title = title_df$title[as.integer(tv_show_id)], 
         rank = title_df$rank[as.integer(tv_show_id)])
final_reviews <- final_reviews %>%
  mutate(tv_show_title = title_df$title[as.integer(tv_show_id)], 
         rank = title_df$rank[as.integer(tv_show_id)])
final_reviews <- final_reviews %>%
  select(-helpful, -unhelpful, -tv_show_title, -rank)

print(final_reviews)
```

```{r}

write.csv(final_reviews, file = "movie_reviews_final.csv")
```


Extracting Amazon Product Reviews
4. Select 5 categories from Amazon and select 30 products from each category.

```{r}
install.packages("rvest")
#}
library(rvest)
library(polite)

```

```{r}

#computers category
url <- "https://www.amazon.com/s?i=computers-intl-ship&rh=n%3A16225007011%2Cp_72%3A4-&s=featured-rank&content-id=amzn1.sym.48dedb24-204f-4fb3-a22a-bd005b512d57&pd_rd_r=825293e6-c0c3-4415-86a6-67dda8ed433a&pd_rd_w=qVEL7&pd_rd_wg=lZyVa&pf_rd_p=48dedb24-204f-4fb3-a22a-bd005b512d57&pf_rd_r=1ER3G2Q97SB5HS078X29&ref=Oct_d_otopr_S"

session <- bow(url,
               user_agent = "Student's Demo Educational")
session

session_page <- scrape(session)
```
```{r}
div_elements <- html_nodes(session_page, 'div.sg-col-4-of-24.sg-col-4-of-12.s-result-item.s-asin.sg-col-4-of-16.sg-col.s-widget-spacing-small.sg-col-4-of-20')
```

```{r}
# Create empty vectors to store data
links <- character()
img_srcs <- character()
titles <- character()
prices <- character()
ratings <- character()
descriptions <- character()
reviews <- character()
```

5. Extract the price, description, ratings and reviews of each product.

```{r}
for (div_element in div_elements) {
  # Find the a element with class="a-link-normal s-no-outline" and get the link
  
  
  a_element <- html_node(div_element, 'a.a-link-normal.s-no-outline')
  link <- ifelse(!is.na(a_element), paste0("https://amazon.com", html_attr(a_element, "href")), '')
  
  
  # Find the img element with class="s-image" and get the link
  img_element <- html_node(div_element, 'img.s-image')
  img_src <- ifelse(!is.na(img_element), html_attr(img_element, "src"), '')
  
  # Find the span element with class="a-size-base-plus a-color-base a-text-normal" and get the title
  title_element <- html_node(div_element, 'span.a-size-base-plus.a-color-base.a-text-normal')
  title <- ifelse(!is.na(title_element), html_text(title_element), '')
  
  # Find the span element with class="a-price-whole" and get the price
  price_element <- html_node(div_element, 'span.a-price-whole')
  price <- ifelse(!is.na(price_element), html_text(price_element), '')
  
  # Find the span element with class="a-icon-alt" and get the ratings
  rating_element <- html_node(div_element, 'span.a-icon-alt')
  rating <- ifelse(!is.na(rating_element), html_text(rating_element), '')
  rating <- gsub("out of 5 stars", "", rating, fixed=TRUE)
  
  description_element <- html_node(div_element, 'span.a-size-base-plus.a-color-base.a-text-normal')
  description <- ifelse(!is.na(description_element), html_text(description_element), '')
  
  review_element <- html_node(div_element, 'span.a-expander-collapsed-height.a-row.a-expander-container.a-expander-partial-collapse-container')
  review <- ifelse(!is.na(review_element), html_text(review_element), '')
  
  # Append data to vectors
  links <- c(links, link)
  img_srcs <- c(img_srcs, img_src)
  titles <- c(titles, title)
  prices <- c(prices, price)
  ratings <- c(ratings, rating)
  descriptions <- c(descriptions, description)
  reviews <- c(reviews, review)
}

```


```{r}
# Create a data frame
computeRs_Products <- data.frame(Links = links, 
                         Images = img_srcs, 
                         Title = titles, 
                         Price = prices, 
                         Rating = ratings,
                         Description = descriptions,
                         Review = reviews) 
computeRs_Products

write.csv(computeRs_Products, "computeRs_Products.csv")
```


6. Describe the data you have extracted.
7. What will be your use case for the data you have extracted?
8. Create graphs regarding the use case. And briefly explain it.
9. Graph the price and the ratings for each category. Use basic plotting functions and ggplot2 package.
10. Rank the products of each category by price and ratings. Explain briefly.
```{r}

```

